{
  "hash": "f83c3120b6ad60d98e4e524e3a564278",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Bayesian Chain Ladder with Bambi\"\ndate: 2025-11-30\nslug: bayesian-chain-ladder-bambi\ncategories: [reserving, bayesian]\ndescription: \"Revisiting the chain ladder example with Bambi, PyMC, and ArviZ using the same triangle as the R-based post.\"\n---\n\nThis post rebuilds the original [Bayesian Chain Ladder](/posts/bayesian-chain-ladder/) analysis with a\nPython-first workflow. Instead of `rstanarm`, we will:\n\n- pull the same loss triangle from the CAS Loss Reserve Database via the Python `chainladder` package,\n- fit the cross-classified negative binomial GLM with [Bambi](https://bambinos.github.io/bambi/) on top of\n  [PyMC](https://www.pymc.io/), and\n- rely on [ArviZ](https://python.arviz.org/) for posterior summaries and diagnostics.\n\nThroughout the post we reuse the R outputs from the prior article so you can see how the Python results line\nup without needing to re-run the original code.\n\n## Data: matching the original triangle\n\n::: {#d107fe6b .cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>12</th>\n      <th>24</th>\n      <th>36</th>\n      <th>48</th>\n      <th>60</th>\n      <th>72</th>\n      <th>84</th>\n      <th>96</th>\n      <th>108</th>\n      <th>120</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1988</th>\n      <td>41,821</td>\n      <td>76,550</td>\n      <td>96,697</td>\n      <td>112,662</td>\n      <td>123,947</td>\n      <td>129,871</td>\n      <td>134,646</td>\n      <td>138,388</td>\n      <td>141,823</td>\n      <td>144,781</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>48,167</td>\n      <td>87,662</td>\n      <td>112,106</td>\n      <td>130,284</td>\n      <td>141,124</td>\n      <td>148,503</td>\n      <td>154,186</td>\n      <td>158,944</td>\n      <td>162,903</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>52,058</td>\n      <td>99,517</td>\n      <td>126,876</td>\n      <td>144,792</td>\n      <td>156,240</td>\n      <td>165,086</td>\n      <td>170,955</td>\n      <td>176,346</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1991</th>\n      <td>57,251</td>\n      <td>106,761</td>\n      <td>133,797</td>\n      <td>154,668</td>\n      <td>168,972</td>\n      <td>179,524</td>\n      <td>187,266</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>59,213</td>\n      <td>113,342</td>\n      <td>142,908</td>\n      <td>165,392</td>\n      <td>179,506</td>\n      <td>189,506</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>59,475</td>\n      <td>111,551</td>\n      <td>138,387</td>\n      <td>160,719</td>\n      <td>175,475</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>65,607</td>\n      <td>110,255</td>\n      <td>137,317</td>\n      <td>159,972</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>56,748</td>\n      <td>96,063</td>\n      <td>122,811</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>52,212</td>\n      <td>92,242</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>43,962</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nThe latest diagonal of this triangle sums to the same $1,310,483 observed in the R output. The original chain\nladder estimate produced an IBNR of $373,432 with a 3.1% coefficient of variation, while the R-based Bayesian\nfit landed at an IBNR of $375,090 and a 3.2% CV. We'll keep those figures in mind as we work through the\nPython model.\n\n## Preparing incremental data for Bambi\n\nBambi expects a long-format dataset. We convert the cumulative triangle to increments, reshape to long form, and\nflag which cells belong to the upper-right portion of the triangle that require prediction.\n\n::: {#600e3e28 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accident_year</th>\n      <th>dev</th>\n      <th>incremental</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1988</td>\n      <td>12</td>\n      <td>41821.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1989</td>\n      <td>12</td>\n      <td>48167.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1990</td>\n      <td>12</td>\n      <td>52058.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1991</td>\n      <td>12</td>\n      <td>57251.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1992</td>\n      <td>12</td>\n      <td>59213.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Fitting the chain ladder GLM with Bambi\n\nWe fit a negative binomial model with an intercept plus categorical accident-year and development effects—the\nsame structure used in the original post. To keep run times manageable we use two chains and 1,000 draws per\nchain.\n\n::: {#4380ffa9 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"1ddcd0f73e374f6babdae716c605830f\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_3%</th>\n      <th>hdi_97%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>10.648</td>\n      <td>0.035</td>\n      <td>10.586</td>\n      <td>10.717</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>414.618</td>\n      <td>572.850</td>\n      <td>1.004</td>\n    </tr>\n    <tr>\n      <th>accident_year[1989]</th>\n      <td>0.146</td>\n      <td>0.033</td>\n      <td>0.085</td>\n      <td>0.206</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>842.756</td>\n      <td>944.160</td>\n      <td>0.999</td>\n    </tr>\n    <tr>\n      <th>accident_year[1990]</th>\n      <td>0.242</td>\n      <td>0.036</td>\n      <td>0.172</td>\n      <td>0.309</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>711.267</td>\n      <td>719.834</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>accident_year[1991]</th>\n      <td>0.370</td>\n      <td>0.038</td>\n      <td>0.299</td>\n      <td>0.442</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>784.555</td>\n      <td>909.125</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>accident_year[1992]</th>\n      <td>0.391</td>\n      <td>0.039</td>\n      <td>0.322</td>\n      <td>0.467</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>798.052</td>\n      <td>874.145</td>\n      <td>1.005</td>\n    </tr>\n    <tr>\n      <th>accident_year[1993]</th>\n      <td>0.371</td>\n      <td>0.043</td>\n      <td>0.291</td>\n      <td>0.455</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>854.046</td>\n      <td>929.378</td>\n      <td>1.003</td>\n    </tr>\n    <tr>\n      <th>accident_year[1994]</th>\n      <td>0.356</td>\n      <td>0.045</td>\n      <td>0.276</td>\n      <td>0.445</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>716.792</td>\n      <td>933.953</td>\n      <td>1.001</td>\n    </tr>\n    <tr>\n      <th>accident_year[1995]</th>\n      <td>0.246</td>\n      <td>0.051</td>\n      <td>0.154</td>\n      <td>0.344</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>1042.878</td>\n      <td>1114.721</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>accident_year[1996]</th>\n      <td>0.186</td>\n      <td>0.059</td>\n      <td>0.076</td>\n      <td>0.299</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>1200.642</td>\n      <td>1213.755</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>accident_year[1997]</th>\n      <td>0.047</td>\n      <td>0.082</td>\n      <td>-0.096</td>\n      <td>0.209</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>1323.893</td>\n      <td>1142.059</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>dev[24]</th>\n      <td>-0.206</td>\n      <td>0.034</td>\n      <td>-0.266</td>\n      <td>-0.137</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>871.752</td>\n      <td>1082.866</td>\n      <td>1.004</td>\n    </tr>\n    <tr>\n      <th>dev[36]</th>\n      <td>-0.745</td>\n      <td>0.034</td>\n      <td>-0.808</td>\n      <td>-0.678</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>723.484</td>\n      <td>1139.556</td>\n      <td>1.003</td>\n    </tr>\n    <tr>\n      <th>dev[48]</th>\n      <td>-1.016</td>\n      <td>0.038</td>\n      <td>-1.086</td>\n      <td>-0.945</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>770.665</td>\n      <td>1189.792</td>\n      <td>1.003</td>\n    </tr>\n    <tr>\n      <th>dev[60]</th>\n      <td>-1.450</td>\n      <td>0.038</td>\n      <td>-1.520</td>\n      <td>-1.378</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>716.672</td>\n      <td>1178.781</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>dev[72]</th>\n      <td>-1.842</td>\n      <td>0.043</td>\n      <td>-1.922</td>\n      <td>-1.762</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>798.927</td>\n      <td>1036.208</td>\n      <td>1.003</td>\n    </tr>\n    <tr>\n      <th>dev[84]</th>\n      <td>-2.147</td>\n      <td>0.046</td>\n      <td>-2.230</td>\n      <td>-2.061</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>1011.148</td>\n      <td>1332.764</td>\n      <td>1.001</td>\n    </tr>\n    <tr>\n      <th>dev[96]</th>\n      <td>-2.346</td>\n      <td>0.050</td>\n      <td>-2.441</td>\n      <td>-2.253</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>932.087</td>\n      <td>949.459</td>\n      <td>1.001</td>\n    </tr>\n    <tr>\n      <th>dev[108]</th>\n      <td>-2.506</td>\n      <td>0.058</td>\n      <td>-2.621</td>\n      <td>-2.407</td>\n      <td>0.002</td>\n      <td>0.001</td>\n      <td>779.275</td>\n      <td>882.311</td>\n      <td>1.002</td>\n    </tr>\n    <tr>\n      <th>dev[120]</th>\n      <td>-2.653</td>\n      <td>0.083</td>\n      <td>-2.816</td>\n      <td>-2.507</td>\n      <td>0.003</td>\n      <td>0.002</td>\n      <td>975.849</td>\n      <td>1131.176</td>\n      <td>1.001</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nArviZ makes it straightforward to inspect the fitted effects. The posterior means of the development\nparameters mirror the R-based link ratios, reinforcing that we are estimating the same cross-classified GLM.\n\n::: {#b142484d .cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\narray([<Axes: title={'center': '94.0% HDI'}>], dtype=object)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){}\n:::\n:::\n\n\n## Predicting the unobserved cells\n\nWe now draw from the posterior predictive distribution for the upper-right triangle. The resulting samples let\nus aggregate accident-year reserves and compare them to the R outputs.\n\n::: {#3459994d .cell execution_count=5}\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accident_year</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>cv</th>\n      <th>latest_paid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1989</td>\n      <td>3446.2220</td>\n      <td>381.051175</td>\n      <td>0.110571</td>\n      <td>162903.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990</td>\n      <td>8175.3530</td>\n      <td>629.538458</td>\n      <td>0.077004</td>\n      <td>176346.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1991</td>\n      <td>15139.8520</td>\n      <td>960.055843</td>\n      <td>0.063412</td>\n      <td>187266.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1992</td>\n      <td>22740.5845</td>\n      <td>1245.752161</td>\n      <td>0.054781</td>\n      <td>189506.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1993</td>\n      <td>31950.9575</td>\n      <td>1742.643281</td>\n      <td>0.054541</td>\n      <td>175475.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1994</td>\n      <td>45607.7375</td>\n      <td>2380.651393</td>\n      <td>0.052198</td>\n      <td>159972.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1995</td>\n      <td>60363.6955</td>\n      <td>3533.341381</td>\n      <td>0.058534</td>\n      <td>122811.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1996</td>\n      <td>80967.9675</td>\n      <td>5270.660732</td>\n      <td>0.065096</td>\n      <td>92242.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1997</td>\n      <td>106750.6195</td>\n      <td>9178.185181</td>\n      <td>0.085978</td>\n      <td>43962.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>total</td>\n      <td>375142.9890</td>\n      <td>12801.201699</td>\n      <td>0.034124</td>\n      <td>1455264.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe Bambi-based estimate yields a total IBNR of roughly $375,000 with a 3.4% CV, landing within a few basis\npoints of the R-based Bayesian fit ($375,090 IBNR and 3.2% CV) and only 0.4% above the traditional chain ladder\nestimate ($373,432 IBNR and 3.1% CV).\n\n## Posterior predictive check\n\nTo confirm the model is generating reasonable incremental values, we compare the observed increments to draws\nfrom the posterior predictive distribution for the observed cells.\n\n::: {#f4a0a9b3 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\nThe posterior predictive distribution comfortably envelopes the realized increments, suggesting the negative\nbinomial GLM is flexible enough for this triangle while staying consistent with the earlier R-based results.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"1ddcd0f73e374f6babdae716c605830f\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_ddfadd7d67b44f4bb7b927b853c0cb53\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">                                                                                                                   \\n <span style=\\\"font-weight: bold\\\"> Progress                 </span> <span style=\\\"font-weight: bold\\\"> Draws </span> <span style=\\\"font-weight: bold\\\"> Divergences </span> <span style=\\\"font-weight: bold\\\"> Step size </span> <span style=\\\"font-weight: bold\\\"> Grad evals </span> <span style=\\\"font-weight: bold\\\"> Sampling Speed  </span> <span style=\\\"font-weight: bold\\\"> Elapsed </span> <span style=\\\"font-weight: bold\\\"> Remaining </span> \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.367       7            2362.79 draws/s   0:00:00   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.387       7            2337.39 draws/s   0:00:00   0:00:00    \\n                                                                                                                   \\n</pre>\\n\",\"text/plain\":\"                                                                                                                   \\n \\u001b[1m \\u001b[0m\\u001b[1mProgress                \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDraws\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDivergences\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mStep size\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mGrad evals\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mSampling Speed \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mElapsed\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mRemaining\\u001b[0m\\u001b[1m \\u001b[0m \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.367       7            2362.79 draws/s   0:00:00   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.387       7            2337.39 draws/s   0:00:00   0:00:00    \\n                                                                                                                   \\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"ddfadd7d67b44f4bb7b927b853c0cb53\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}